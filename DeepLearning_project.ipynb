{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing modules","metadata":{}},{"cell_type":"code","source":"# ğŸ”§ 1) install (Ù‡Ù…ÙˆÙ† Ø®Ø· Ù‚Ø¨Ù„ÛŒ)\n!pip install --quiet transformers accelerate bitsandbytes sentence-transformers faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T17:46:36.960494Z","iopub.execute_input":"2025-07-14T17:46:36.960747Z","iopub.status.idle":"2025-07-14T17:48:10.335334Z","shell.execute_reply.started":"2025-07-14T17:46:36.960726Z","shell.execute_reply":"2025-07-14T17:48:10.334425Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Section 1 : Chat bot core","metadata":{}},{"cell_type":"code","source":"# hugging fac token\n# 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","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T17:49:19.224906Z","iopub.execute_input":"2025-07-14T17:49:19.225203Z","iopub.status.idle":"2025-07-14T17:49:19.229069Z","shell.execute_reply.started":"2025-07-14T17:49:19.225181Z","shell.execute_reply":"2025-07-14T17:49:19.228406Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport torch, gc, os\nfrom huggingface_hub import login\n\nlogin(\"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\")\n\nmodel_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\ntokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n\nbnb_cfg = BitsAndBytesConfig(load_in_4bit=True,\n                             bnb_4bit_compute_dtype=torch.float16,\n                             bnb_4bit_use_double_quant=True,\n                             bnb_4bit_quant_type=\"nf4\")\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    device_map=\"auto\",\n    quantization_config=bnb_cfg,\n    trust_remote_code=True,\n).eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T17:49:21.524542Z","iopub.execute_input":"2025-07-14T17:49:21.525243Z","iopub.status.idle":"2025-07-14T17:51:15.265404Z","shell.execute_reply.started":"2025-07-14T17:49:21.525216Z","shell.execute_reply":"2025-07-14T17:51:15.264851Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7479e2633af483388d4f2b6d7e57895"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbeb93e890864dfda23a21a6a1f24495"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49110636ae414b948c84d80ad391c98c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b0e84ec39794e54879c4c085c18f278"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d94b10fc5f5491984caeb064fe74cb1"}},"metadata":{}},{"name":"stderr","text":"2025-07-14 17:49:42.327760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752515382.678261      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752515382.783248      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3af6fb85aeb14c7bb60bf17662985422"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7869dbd0dd16400083e381659140bc23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b795b5ec17e41bba975d9038cad6f5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc5839b833774f6195611547ea6ca500"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8fecb3df96e4ff2aae7163a36f70f68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5517a81d0ee48c1abe6d2e0fbea9074"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d38ac4d3323245b0b1e1102b1b3f10cc"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import json, gc, os, time\nfrom collections import deque\nfrom typing import List, Dict\n\n# ------------ tweakables -----------------------------------------------------\nSYSTEM_PROMPT = \"You are a helpful AI assistant.\"\nMAX_CTX_TOKENS   = 8000 - 512        # keep 512 tokens headroom\nSUMMARISE_AT_TOK = 6000              # start summarising above this\nCHUNK_SIZE       = 12                # summarise 12 oldest turns each time\nLOG_FILE         = \"chatlog.jsonl\"   # optional disk log\n# -----------------------------------------------------------------------------\n\ndef num_tokens(text: str) -> int:\n    # helper for quick token counting\n    return len(tokenizer.encode(text))\n\ndef chat_completion(messages: List[Dict],  # messages[-1] must be user\n                    max_new=256, temp=0.7, top_p=0.9):\n    prompt = tokenizer.apply_chat_template(\n        messages, tokenize=False, add_generation_prompt=True\n    )\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    out = model.generate(\n        **inputs,\n        max_new_tokens=max_new,\n        temperature=temp,\n        top_p=top_p,\n        eos_token_id=tokenizer.eos_token_id\n    )\n    reply = tokenizer.decode(out[0][inputs.input_ids.shape[1]:],\n                             skip_special_tokens=True).strip()\n    return reply\n\n\nclass MemoryChatbot:\n    \"\"\"Keeps the last N turns verbatim and auto-summarises earlier ones.\"\"\"\n\n    def __init__(self,\n                 system_prompt: str = SYSTEM_PROMPT,\n                 max_ctx_tokens: int = MAX_CTX_TOKENS,\n                 summarise_at: int = SUMMARISE_AT_TOK,\n                 chunk_size: int = CHUNK_SIZE):\n        self.system_prompt = system_prompt\n        self.max_ctx_tokens = max_ctx_tokens\n        self.summarise_at   = summarise_at\n        self.chunk_size     = chunk_size\n\n        self.history = deque()    # list of {\"role\":..., \"content\":...}\n        self.memo    = \"\"         # running summary of trimmed turns\n\n    # ------------- public API -------------------------------------------------\n    def ask(self, user_msg: str) -> str:\n        \"\"\"Main entry: add user message â†’ maybe summarise â†’ get reply.\"\"\"\n        self._append(\"user\", user_msg)\n        self._maybe_summarise()\n        reply = self._generate_reply(user_msg)\n        self._append(\"assistant\", reply)\n        return reply\n    # -------------------------------------------------------------------------\n\n    # ------------- internal helpers ------------------------------------------\n    def _append(self, role, content):\n        self.history.append({\"role\": role, \"content\": content})\n        self._disk_log(role, content)\n\n    def _current_messages(self) -> List[Dict]:\n        msgs = [{\"role\": \"system\", \"content\": self.system_prompt}]\n        if self.memo:\n            msgs.append({\"role\": \"assistant\",\n                         \"content\": f\"[CONTEXT SUMMARY]\\n{self.memo}\"})\n        msgs.extend(self.history)\n        return msgs\n\n    def _prompt_tokens(self) -> int:\n        txt = tokenizer.apply_chat_template(self._current_messages(),\n                                            tokenize=False)\n        return num_tokens(txt)\n\n    def _maybe_summarise(self):\n        \"\"\"If conversation is getting heavy, summarise oldest chunk.\"\"\"\n        while self._prompt_tokens() > self.summarise_at and len(self.history) > self.chunk_size:\n            chunk = list(self.history)[:self.chunk_size]\n            chunk_txt = \"\\n\".join(f\"{m['role']}: {m['content']}\" for m in chunk)\n\n            summary_prompt = [\n                {\"role\": \"system\",\n                 \"content\": \"You are a summarisation assistant.\"},\n                {\"role\": \"user\",\n                 \"content\":\n                 (\"Summarise the following conversation in â‰¤8 bullet points, \"\n                  \"preserve all factual details:\\n\\n\" + chunk_txt)}\n            ]\n            summary = chat_completion(summary_prompt, max_new=160, temp=0.3)\n\n            # remove chunk & prepend summary\n            for _ in range(self.chunk_size):\n                self.history.popleft()\n            self.memo = (self.memo + \"\\n\" + summary).strip()\n\n            # free GPU RAM\n            gc.collect(); torch.cuda.empty_cache()\n\n            if self._prompt_tokens() < self.max_ctx_tokens:\n                break\n\n    def _generate_reply(self, user_msg):\n        msgs = self._current_messages()\n        reply = chat_completion(msgs)\n        gc.collect(); torch.cuda.empty_cache()\n        return reply\n\n    def _disk_log(self, role, content):\n        if LOG_FILE:\n            with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n                json.dump({\"ts\": time.time(), \"role\": role,\n                           \"content\": content}, f, ensure_ascii=False)\n                f.write(\"\\n\")\n    # -------------------------------------------------------------------------\n\n\n# ----------------------- quick demo ------------------------------------------\nbot = MemoryChatbot()\n\nqs = [\"Hey there! How are you?\",\n      \"Can you suggest two contemporary architecture books?\",\n      \"What chapters do those books include?\"]\n\nfor q in qs:\n    print(\"ğŸ‘¤\", q)\n    print(\"ğŸ¤–\", bot.ask(q), \"\\n\")\n\n# keep chatting â€¦ the bot will start summarising automatically\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T17:43:58.088522Z","iopub.execute_input":"2025-07-14T17:43:58.088838Z","iopub.status.idle":"2025-07-14T17:44:45.063339Z","shell.execute_reply.started":"2025-07-14T17:43:58.088814Z","shell.execute_reply":"2025-07-14T17:44:45.062402Z"}},"outputs":[{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"ğŸ‘¤ Hey there! How are you?\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"ğŸ¤– I'm just an AI, so I don't have feelings or the ability to experience emotions. I'm here to help answer any questions you might have and provide information on various topics. How can I assist you today? \n\nğŸ‘¤ Can you suggest two contemporary architecture books?\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"ğŸ¤– Absolutely! Here are two contemporary architecture books that have received critical acclaim and are highly recommended:\n\n1. \"Contemporary Architecture: A World of Design\" by Philip Johnson and Kirkland Schneider: This book provides an in-depth look at contemporary architecture from around the world, featuring stunning photographs and insightful commentary from two of the field's leading experts.\n2. \"The Architecture of Happiness\" by Alain de Botton: This thought-provoking book explores the relationship between architecture and human emotion, offering a unique perspective on how buildings and spaces can influence our moods and well-being.\n\nBoth of these books offer fresh perspectives on contemporary architecture and are sure to inspire and inform anyone with an interest in the field. \n\nğŸ‘¤ What chapters do those books include?\nğŸ¤– I'd be happy to provide you with some information about the chapters in each of the books I recommended, but please keep in mind that I don't have access to the actual books themselves, so I can only provide a general idea based on the information available online and in book descriptions.\n\n1. \"Contemporary Architecture: A World of Design\" by Philip Johnson and Kirkland Schneider: This book is divided into several sections, each focusing on a different region of the world. Some of the chapters include:\n* Europe\n* North America\n* South America\n* Asia\n* Africa and the Middle East\n* Australia and the Pacific\n\nEach chapter features a selection of contemporary architectural projects from that region, along with detailed descriptions and analysis by the authors.\n\n2. \"The Architecture of Happiness\" by Alain de Botton: This book is not organized into traditional chapters in the same way that a standard architecture book might be. Instead, it is divided into thematic sections that explore various aspects of the relationship between architecture and happiness. Some of the topics covered include:\n* The importance of architecture in shaping our moods and emotions\n* The role of architecture in creating a sense of home \n\n","output_type":"stream"}],"execution_count":11}]}